{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af67835-0be2-4ee0-b175-96d046118df4",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9e66568-fa9f-4ea1-8898-b0d7a8d0cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import TypeVar, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b3695d-7b1f-4725-8439-0e18c15bb2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = TypeVar('X')  # generic type to represent a data point\n",
    "\n",
    "def split_data(data: List[X], prob: float) -> Tuple[List[X], List[X]]:\n",
    "    \"\"\"Split data into fractions [prob, 1 - prob]\"\"\"\n",
    "    data = data[:]                    # Make a shallow copy\n",
    "    random.shuffle(data)              # because shuffle modifies the list.\n",
    "    cut = int(len(data) * prob)       # Use prob to find a cutoff\n",
    "    return data[:cut], data[cut:]     # and split the shuffled list there.\n",
    "\n",
    "data = [n for n in range(1000)]\n",
    "train, test = split_data(data, 0.75)\n",
    "\n",
    "# The proportions should be correct\n",
    "assert len(train) == 750\n",
    "assert len(test) == 250\n",
    "\n",
    "# And the original data should be preserved (in some order)\n",
    "assert sorted(train + test) == data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b486ff0d-6ed5-4fd9-b7d1-f4ae9b2de591",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = TypeVar('Y')  # generic type to represent output variables\n",
    "\n",
    "def train_test_split(xs: List[X],\n",
    "                     ys: List[Y],\n",
    "                     test_pct: float) -> Tuple[List[X], List[X], List[Y], List[Y]]:\n",
    "    # Generate the indices and split them.\n",
    "    idxs = [i for i in range(len(xs))]\n",
    "    train_idxs, test_idxs = split_data(idxs, 1 - test_pct)\n",
    "\n",
    "    return ([xs[i] for i in train_idxs],  # x_train\n",
    "            [xs[i] for i in test_idxs],   # x_test\n",
    "            [ys[i] for i in train_idxs],  # y_train\n",
    "            [ys[i] for i in test_idxs])   # y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e87ed2c-7557-4f7e-b615-71d67c2ab2bd",
   "metadata": {},
   "source": [
    "We want to make sure our code works right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a95a979-a510-45a5-9636-1ac8c0d35729",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = [x for x in range(1000)] # xs are 1 ... 1000\n",
    "ys = [2 * x for x in xs]      # each y_i is twice x_i\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.25)\n",
    "\n",
    "# Check that the proportions are correct\n",
    "assert len(x_train) == len(y_train) == 750\n",
    "assert len(x_test) == len(y_test) == 250\n",
    "\n",
    "# Check that the corresponding data point are paired correctly\n",
    "assert all(y == 2 * x for x, y in zip(x_train, y_train))\n",
    "assert all(y == 2 * x for x, y in zip(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10141393-1337-4adb-8ab0-33e4feda8c3c",
   "metadata": {},
   "source": [
    "After which we can do something like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527bb71-f850-4de4-8949-14e1290e57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SomeKindOfModel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(xs, ys, 0.33)\n",
    "model.train(x_train, y_train)\n",
    "performance = model.test(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c34323-e2f3-4134-87dc-7eef5d13afee",
   "metadata": {},
   "source": [
    "## Correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490e8bf3-f3e2-425e-8399-05700fa4ff0b",
   "metadata": {},
   "source": [
    "Given a set of labeled data and such a predictive model, every data point lies in one of four categories:\n",
    "    \n",
    "* True positive\n",
    "   - “This message is spam, and we correctly predicted spam.”\n",
    "    \n",
    "* False positive (Type 1 error)\n",
    "   - “This message is not spam, but we predicted spam.”\n",
    "    \n",
    "* False negative (Type 2 error)\n",
    "   - “This message is spam, but we predicted not spam.”\n",
    "    \n",
    "* True negative\n",
    "   - “This message is not spam, and we correctly predicted not spam.”\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b331fa-2386-45f1-8f9b-1dbd67d2af08",
   "metadata": {},
   "source": [
    "**accuracy** is defined as the fraction of correct predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a6164ac-8486-4d3b-9183-04f3bece9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(tp: int, fp: int, fn: int, tn:int) -> float:\n",
    "    \n",
    "    correct = tp + tn\n",
    "    total = tp + fp + fn + tn\n",
    "    \n",
    "    return correct/total\n",
    "\n",
    "assert accuracy(70, 4930, 13930, 981070) == 0.98114"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49397642-5873-4856-864b-3daee26bf8b0",
   "metadata": {},
   "source": [
    "It’s common to look at the combination of **precision** and **recall**. **recision** measures how accurate our **positive** predictions were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc2aab1-13a2-4faf-a553-da843dab0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fp)\n",
    "\n",
    "assert precision(70, 4930, 13930, 981070) == 0.014"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f462d89f-8de0-465b-bb44-daf73385e1d8",
   "metadata": {},
   "source": [
    "**recall** measures what fraction of the positives our model identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d871c583-e4dd-4621-86a6-67ee6f3be3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    return tp / (tp + fn)\n",
    "\n",
    "assert recall(70, 4930, 13930, 981070) == 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fa30e-3ae3-4f05-a5dc-1a02e4cecdb5",
   "metadata": {},
   "source": [
    "Sometimes precision adn recall are combined into the **F1 score**, which is defined as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6b18d3a-7772-47dc-a986-e30643b9113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(tp: int, fp: int, fn: int, tn: int) -> float:\n",
    "    p = precision(tp, fp, fn, tn)\n",
    "    r = recall(tp, fp, fn, tn)\n",
    "\n",
    "    return 2 * p * r / (p + r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06a8673-04c5-4a89-a36f-ab1a3bc3062f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
